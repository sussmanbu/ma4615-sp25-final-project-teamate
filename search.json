[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This page details our data sources, the cleaning process, and provides initial diagnostic plots. For this project, we work with data from the landmark study Systemic Discrimination Among Large U.S. Employers (Kline, Rose, and Walters, 2022). The data was originally collected through a fake resume experiment to investigate patterns of hiring discrimination in large US employers, making it highly relevant to both current social justice issues and policy enforcement efforts."
  },
  {
    "objectID": "data.html#data-sources-and-rationale",
    "href": "data.html#data-sources-and-rationale",
    "title": "Data",
    "section": "Data Sources and Rationale",
    "text": "Data Sources and Rationale\n\nExperimental, Main Dataset\n\nSource: The dataset is available on Harvard Dataverse and was published alongside the study “Systemic Discrimination Among Large U.S. Employers”.\nLink to original data source\nPurpose: The data were collected to examine whether hiring discrimination is endemic to particular firms and to quantify the impact of factors such as race, gender, and age on callback rates.\nWhy this Data: We selected this dataset because it not only addresses pressing issues of discrimination and equity but also includes rich information (e.g., date, location, and applicant demographics) that supports extensive exploratory and inferential analysis.\n\n\n\nCensus Population, Demographic Data\n\nSource: The census data was obtained from the United States Census Bureau.\nLink to census data and Link to census data\nPurpose: The census data provides demographic information about the population in each state, which is essential for understanding the the size of the population in each state and how it relates to labor market dynamics.\nWhy this Data: The census data is crucial for contextualizing the experimental data, allowing us to compare relative submission versus the number of applications in the study. This enables us to assess the representativeness of the sample and to explore potential biases in the data."
  },
  {
    "objectID": "data.html#data-files-and-variables",
    "href": "data.html#data-files-and-variables",
    "title": "Data",
    "section": "Data Files and Variables",
    "text": "Data Files and Variables\n\nExperimental Dataset\nThe project focuses on a single dataset that was processed and saved as an RDS file (cleaned_data.rds). Some Key variables include:\n\nage_at_sub: Age of the applicant at the time of submission.\nmonth and year: Date components of when applications were submitted.\nstate: Geographic information about the submission.\nrace: Race of the applicant.\ncb: Binary indicator for whether an applicant received a callback (1 = Yes, 0 = No).\nAdditional variables (e.g., gender, education, etc.) are available and grouped.\n\nFor a detailed account of variable definitions and transformations, please refer to our cleaning script.\n\n\nCensus Dataset\nTo see how we combine the census data with the application data, please refer to our census cleaning script"
  },
  {
    "objectID": "data.html#data-cleaning-process",
    "href": "data.html#data-cleaning-process",
    "title": "Data",
    "section": "Data Cleaning Process",
    "text": "Data Cleaning Process\n\nThe raw data was imported, cleaned, and transformed using R. The cleaning process involved:\n\nRenaming variables and recoding factors for clarity.\nRemoving duplicate and inconsistent entries.\nAggregating multiple data files (if applicable) to produce the final cleaned dataset.\nSaving the cleaned dataset as an RDS file for efficient reloading in analyses.\n\nFor census data and aggregation, we follow the process below:\n\nVariables were renamed and factors recoded for clarity.\nDuplicate and inconsistent entries were eliminated.\nIndividual application records were aggregated to the state level.\nThe state-level application data was merged with census population counts to calculate the proportion of applications relative to state populations."
  },
  {
    "objectID": "data.html#diagnostic-plots",
    "href": "data.html#diagnostic-plots",
    "title": "Data",
    "section": "Diagnostic Plots",
    "text": "Diagnostic Plots\nBelow are some initial diagnostic plots generated from the cleaned dataset.\n\nImporting the Cleaned Data\n\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(usmap)) # used for plotting US maps\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")\nmerged_data &lt;- readRDS(\"dataset/merged_data_state_by_year.rds\")\n\n\n\nCheck for outliers in Age at Submission\n\n\n\n\n\n\n\n\n\nAs defined by the authors, the age is uniformly distributed between 20 and 60. This plot confirms that there are no outliers in the age variable.\n\n\nCheck distribution of submissions throughout years\n\n\n\n\n\n\n\n\n\nThis histogram shows the distribution of applications by month and year. The data is aggregated by month and year, allowing us to see trends over time. Notably, data from 2020 March to June is missing, likely due to the COVID-19 pandemic. January 2021 shows the distribution mode, with a significant number of applications submitted during that month.\nThis histogram legitimizes the necessity of controlling for a wave of application in our analysis, as these time trends could be correlated with other variables.\n\n\nDistribution of Submissions by State\n\n\n\n\n\n\n\n\n\nIn this plot, we can see that California has the highest number of applications, followed by Texas and Florida. This distribution is important for understanding the geographic representation of our sample and its implications for the analysis.\n\n\nGeographic Distribution of Submissions Versus Population By State\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe above two plots show the geographic distribution of applications and population size across states. The first plot shows the mean population size of each state from 2019 to 2021, while the second plot shows the total number of applications within each state during the same period.\nThe takeaway from these plots is that the relative number of applications across states largely reflects the size of the population in each state. In particular, states in the West, Northeast, and Southeast—regions known for having larger populations—consistently show higher application counts, aligning with the overall demographic distribution across the United States.\n\nThis comes from the original file data.qmd.\nYour first steps in this project will be to find data to work on.\nI recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.\nInitially, you will study one dataset but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable. Data from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components."
  },
  {
    "objectID": "data.html#what-makes-a-good-data-set",
    "href": "data.html#what-makes-a-good-data-set",
    "title": "Data",
    "section": "What makes a good data set?",
    "text": "What makes a good data set?\n\nData you are interested in and care about.\nData where there are a lot of potential questions that you can explore.\nA data set that isn’t completely cleaned already.\nMultiple sources for data that you can combine.\nSome type of time and/or location component."
  },
  {
    "objectID": "data.html#where-to-keep-data",
    "href": "data.html#where-to-keep-data",
    "title": "Data",
    "section": "Where to keep data?",
    "text": "Where to keep data?\nBelow 50mb: In dataset folder\nAbove 50mb: In dataset-ignore folder which you will have to create manually. This folder will be ignored by git so you’ll have to manually sync these files across your team.\n\nSharing your data\nFor small datasets (&lt;50mb), you can use the dataset folder that is tracked by github. Stage and commit the files just like you would any other file.\nFor larger datasets, you’ll need to create a new folder in the project root directory named dataset-ignore. This will be ignored by git (based off the .gitignore file in the project root directory) which will help you avoid issues with Github’s size limits. Your team will have to manually make sure the data files in dataset-ignore are synced across team members.\nYour clean_data.R file in the scripts folder is the file where you will import the raw data that you download, clean it, and write .rds file(s) (using write_rds) that you’ll load in your analysis page. If desirable, you can have multiple scripts that produce different derived data sets, just make sure to link to them on this page.\nYou should never use absolute paths (eg. /Users/danielsussman/path/to/project/ or C:\\MA415\\\\Final_Project\\). Instead, use the here function from the here package to avoid path problems.\n\n\nClean data script\nThe idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them. This file might create a derivative data set that you then use for your subsequent analysis. Note that you don’t need to run this script from every post/page. Instead, you can load in the results of this script, which will usually be .rds files. In your data page you’ll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes."
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones, possibly grouping together variables that are similar, and summarize the rest.\nUse figures or tables to help explain the data. For example, showing a histogram or bar chart for a particularly important variable can provide a quick overview of the values that variable tends to take.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your clean_data.R file.\nRename variables and recode factors to make data more clear.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nCode Reference:"
  },
  {
    "objectID": "analysis.html#loading-data",
    "href": "analysis.html#loading-data",
    "title": "Analysis",
    "section": "Loading data",
    "text": "Loading data\n\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\nsuppressPackageStartupMessages(library(fixest))\nsuppressPackageStartupMessages(library(usmap))\nsuppressPackageStartupMessages(library(lfe))    \nsuppressPackageStartupMessages(library(lmtest))\nsuppressPackageStartupMessages(library(sandwich)) \nsuppressPackageStartupMessages(library(multiwayvcov))\nsuppressPackageStartupMessages(library(here))\nsuppressPackageStartupMessages(library(gtsummary))\nsuppressPackageStartupMessages(library(htmltools))\nsuppressPackageStartupMessages(library(broom))\nsuppressPackageStartupMessages(library(stringr))\n\ndata &lt;- readRDS(here::here(\"dataset/cleaned_data.rds\"))"
  },
  {
    "objectID": "analysis.html#motivation",
    "href": "analysis.html#motivation",
    "title": "Analysis",
    "section": "Motivation",
    "text": "Motivation\nDespite decades of regulatory and legal efforts to eliminate hiring discrimination, numerous field experiments continue to document persistent gaps in employer callback rates by race. In the study by Rose et al. (2022), the large-scale fake resume experiment among Fortune 500 firms in the US enables us to investigate the extent of taste-based discrimination in hiring practices.\nIn a nutshell, the study sends fake resumes with randomly assigned characteristics to entry-level positions among large U.S. employers. This is an example of how a sample of resumes looks like: \n\nNote: sourced from Figure A1: Examples of applicant resumes in the Rose et al. (2022) paper."
  },
  {
    "objectID": "analysis.html#research-questions",
    "href": "analysis.html#research-questions",
    "title": "Analysis",
    "section": "Research Questions",
    "text": "Research Questions\nThere is a famous saying:\n\nCorrelation does not imply causation.\n\nThis is especially true when it comes to the dialogue of racial disparity from a data-driven point of view. In the previous correlation-based analysis, the discrimination gap may have been misspecified due to omitted variable bias (OVB). For instance, instead of taste-based discrimination, labor market outcome inequality may be driven by different levels of educational attainment, work experience, or other factors that are not controlled for.\nThis analysis leverages the powerful experimental data and codes from the Rose et al. (2022) paper to estimate the causal impact of being Black on the probability of receiving a callback.\nThe analysis is based on the following research questions:\n\nDoes tasted-based discrimination cause differential labor market outcomes in the U.S?\n\n\nIf so, how large is the magnitude?\n\n\nIs there evidence of intersectional heterogeneity—that is, does the magnitude of the Black callback penalty vary by another trait?\n\n\n\nIf so, how large is the magnitude?\n\n\nDo firm‑ or month‑level shocks attenuate or amplify measured discrimination?"
  },
  {
    "objectID": "analysis.html#summary-statistics",
    "href": "analysis.html#summary-statistics",
    "title": "Analysis",
    "section": "Summary Statistics",
    "text": "Summary Statistics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nAll Firms - Black\nN = 9,1411\nAll Firms - White\nN = 9,1341\nBalanced - Black\nN = 32,6651\nBalanced - White\nN = 32,7031\n\n\n\n\nAny contact\n1,972 (22%)\n2,103 (23%)\n7,647 (23%)\n8,380 (26%)\n\n\nAny voicemail contact\n1,246 (14%)\n1,383 (15%)\n5,410 (17%)\n6,052 (19%)\n\n\nAny email contact\n256 (2.8%)\n263 (2.9%)\n1,357 (4.2%)\n1,414 (4.3%)\n\n\nAny text message contact\n470 (5.1%)\n457 (5.0%)\n880 (2.7%)\n914 (2.8%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\nThe first panel (“All Firms”) shows that Black applicants receive any form of contact in 22 percent of applications versus 23 percent for White applicants—a modest raw gap. When we restrict to the “Balanced” sample, the disparity widens: 23 percent versus 26 percent. Similar patterns hold for voicemails (17% vs 19%) and email/text contacts. These descriptive gaps motivate our causal estimation below and suggest that, even with the same pool of job postings, Black applicants face lower call‑back rates across multiple channels."
  },
  {
    "objectID": "analysis.html#descriptive-evidence-by-applicants-first-name",
    "href": "analysis.html#descriptive-evidence-by-applicants-first-name",
    "title": "Analysis",
    "section": "Descriptive Evidence by Applicants First Name",
    "text": "Descriptive Evidence by Applicants First Name\n\n\n\n\n\n\n\n\n\nThis figure shows mean contact rates by applicant first name, organized by race and gender group. The horizontal bars show race group mean contact rates. We can see that, on average, black names receive fewer 30-day callbacks than white names."
  },
  {
    "objectID": "analysis.html#effect-of-taste-based-discrimination-on-contact-rates",
    "href": "analysis.html#effect-of-taste-based-discrimination-on-contact-rates",
    "title": "Analysis",
    "section": "Effect of Taste-Based Discrimination on Contact Rates",
    "text": "Effect of Taste-Based Discrimination on Contact Rates\nDue to the nature of experimental data, we can estimate the causal effect of large employers’ taste-based discrimination on applicant labor market outcomes.\n\nModel Specification\nThe code estimates the causal effect of being Black on the probability of receiving a callback, controlling for a vector of other resume characteristics. Formally, two specifications:\n\nLinear probability model (OLS):\n\n\nwith controls for all sample\nwith controls for a balanced sample\ntwo-way fixed effects for all sample\ntwo-way fixed effects for a balanced sample\n\n\nLogistic regression\n\n\nwith controls for all sample\nwith controls for a balanced sample\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\nCall Back Prob.\n\n\n\nOLS\nlogistic\nOLS\nlogistic\n\n\n\n(1)\n(2)\n(3)\n(4)\n(5)\n(6)\n\n\n\n\n\nBlack\n-0.021***\n-0.020***\n-0.115***\n-0.022***\n-0.022***\n-0.123***\n\n\n\n(0.003)\n(0.003)\n(0.016)\n(0.003)\n(0.003)\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\nFemale\n0.0002\n\n0.001\n-0.0002\n\n-0.002\n\n\n\n(0.003)\n\n(0.016)\n(0.003)\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\nOver 40\n-0.006**\n\n-0.033**\n-0.005\n\n-0.027\n\n\n\n(0.003)\n\n(0.016)\n(0.003)\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\nPolitical club\n-0.002\n\n-0.010\n-0.003\n\n-0.017\n\n\n\n(0.007)\n\n(0.041)\n(0.008)\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\nAcademic club\n0.010\n\n0.052\n0.006\n\n0.028\n\n\n\n(0.007)\n\n(0.041)\n(0.008)\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\nLGBTQ club\n-0.005\n\n-0.029\n-0.00004\n\n-0.001\n\n\n\n(0.005)\n\n(0.030)\n(0.006)\n\n(0.034)\n\n\n\n\n\n\n\n\n\n\n\nSame‑gender pronouns\n-0.014*\n\n-0.077*\n-0.013\n\n-0.068\n\n\n\n(0.007)\n\n(0.041)\n(0.008)\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\nGender‑neutral pronouns\n-0.010\n\n-0.057\n-0.017**\n\n-0.095**\n\n\n\n(0.007)\n\n(0.041)\n(0.009)\n\n(0.048)\n\n\n\n\n\n\n\n\n\n\n\nAssociate degree\n0.001\n\n0.007\n0.003\n\n0.014\n\n\n\n(0.003)\n\n(0.016)\n(0.003)\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample\nAll Firms\nAll Firms\nAll Firms\nBalanced\nBalanced\nBalanced\n\n\nFirm FE\nNo\nYes\nNo\nNo\nYes\nNo\n\n\nMonth FE\nNo\nYes\nNo\nNo\nYes\nNo\n\n\nObservations\n83,643\n83,643\n83,643\n65,368\n65,368\n65,368\n\n\nR2\n0.024\n0.151\n\n0.024\n0.130\n\n\n\nAdjusted R2\n0.024\n0.150\n\n0.024\n0.129\n\n\n\nF Statistic\n126.977*** (df = 16; 83626)\n120.790*** (df = 123; 83519)\n\n101.025*** (df = 16; 65351)\n112.290*** (df = 87; 65280)\n\n\n\n\n\n\nNote:\n*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\nClustered SEs by job\n\n\n\nAcross all specifications, the coefficient on Black is consistently negative and highly significant. In the simplest linear probability model (column 1), being Black reduces the probability of any callback by about 2.1 percentage points (SE=0.3pp). When we add firm and month fixed effects (column 2), the gap narrows only slightly to 2.0 pp, indicating that sorting of Black resumes into “easier” or “tougher” firms/months accounts for very little of the raw disparity. In the balanced‐sample OLS (column 5), the Black penalty is essentially unchanged at 2.2 pp. The corresponding logistic regressions (columns 3 and 6) imply a roughly 11–12 percent reduction in the odds of callback for Black applicants, again robust to fixed effects and sample restrictions.\nAmong the other resume traits, Over 40 exhibits a modest negative effect in the unrestricted sample (–0.6 pp) but loses significance in the balanced sample. Gender itself (Female) has no discernible callback penalty or bonus. Signals like political, academic, or LGBTQ club affiliations never reach conventional significance, nor does holding an associate degree. Interestingly, the use of same‑gender pronouns on the résumé is associated with a small but borderline significant callback penalty in the basic models (–1.4 pp), and the neutral‑pronoun penalty becomes significant in the balanced OLS (–1.7 pp). This hints that nontraditional pronoun signaling may carry a slight cost in this context, though the effect sizes are small relative to the race gap.\nThe model fit remains modest: R² climbs from just 2.4 percent without fixed effects to about 15 percent once we absorb firm‐and‐month variation, underscoring that much of the callback decision is driven by idiosyncratic job‐level factors and unobserved employer preferences. All standard errors are clustered at the job level, and the F‑statistics confirm the joint significance of the regressors.\nKey takeaway : Even after controlling for a broad vector of resume characteristics and accounting for firm/month heterogeneity, Black applicants face a persistent 2pp lower callback rate—roughly a 12 percent relative penalty—highlighting taste‑based discrimination in large‑firm hiring.\n\n\nVisualization of OLS Estimates\n\n\n\n\n\n\n\n\n\nWe can observe that the coefficient estimates for the Black variable are negative and significant across all samples since the 95% confidence intervals do not include 0. Also, gender-neutral pronoun estimates are significant in the balanced sample."
  },
  {
    "objectID": "analysis.html#heterogeneity-analysis",
    "href": "analysis.html#heterogeneity-analysis",
    "title": "Analysis",
    "section": "Heterogeneity Analysis",
    "text": "Heterogeneity Analysis\nIn this section, we use interaction terms to explore how the effect of being Black on labor market outcomes varies across different characteristics of the resumes.\n\n\n\n\n\n\n\n\n\nAlthough we don’t find a significant gender penalty in the baseline model, the black-female interaction remains significant across sample restrictions, indicating that Black women experience an extra callback penalty beyond what the additive race and gender effects predict.\nThe interaction term between Black and gender‑neutral pronouns is also significant in the balanced sample. In other words, Black applicants who include gender‑neutral pronouns on their résumé face an additional callback penalty."
  },
  {
    "objectID": "analysis.html#conclusion",
    "href": "analysis.html#conclusion",
    "title": "Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis leverages a large-scale résumé audit experiment to estimate the causal effect of race on callback rates at Fortune 500 firms. Across all linear probability and logit specifications—both unrestricted and balanced samples—being Black reduces the probability of any form of contact by roughly 2 percentage points (≈ 11–12 percent relative penalty), a gap that remains unchanged once we absorb firm and month fixed effects.\nPronoun usage carries a small penalty, and in the balanced sample the Black × Gender‑Neutral Pronouns and Black × Female interaction are also significant, indicating an extra penalty for Black applicants who signal intersecionality.\n\n\nLimitations\n\nExternal validity: Firms in the Fortune 500 may not reflect smaller or mid‑sized employers’ behavior. The generalizability of these results to other sectors or regions is uncertain. Future work could extend this analysis to a broader set of firms, including smaller employers or those in different industries.\nAdditional outcome: Social capital and social networks are important in the hiring process. Future work could explore how race affect social capital accumulation and its impact on hiring outcomes. For example, do Black applicants have fewer connections to employees at the firms they apply to? Do they receive fewer referrals or recommendations from friends or family members?\n\nA new study using LinkedIn: LinkedOut? A Field Experiment on Discrimination in Job Network Formation\n\nMore racial variation: Since this study only covers black-white differences, it would be interesting to see how other racial groups are affected. For example, do Asian applicants face similar or different discrimination patterns compared to Black applicants? Do Hispanic applicants experience different callback rates based on their names or other characteristics?"
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data.\n\n\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "This comes from the index.qmd file; Blog codes are in the posts directory.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 7: Interactive Analysis\n\n\n\n\n\nA self-contained Shiny app. \n\n\n\n\n\nApr 22, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 6: Wrapping Up the Analysis\n\n\n\n\n\nWrapping up original analysis in the paper. \n\n\n\n\n\nApr 16, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 5: Geographic Analysis of Experiment and Census Data\n\n\n\n\n\nLeverage Census data to check the geographical distribution of the experimental design.. \n\n\n\n\n\nApr 7, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 4: Extended Statistical Modeling\n\n\n\n\n\nApply some statistical modeling to our data. \n\n\n\n\n\nMar 31, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 3: Extended Analysis and Equity Considerations\n\n\n\n\n\nPreliminary data exploration and explore the structure of the data. \n\n\n\n\n\nMar 24, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 2: Data Loading, Cleaning, and Diagnostic Plots\n\n\n\n\n\nThis blog shows the background of our data and how we visualize it. \n\n\n\n\n\nMar 17, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 1: Data Progress\n\n\n\n\n\nDescription of datasets found. \n\n\n\n\n\nFeb 24, 2025\n\n\nTEAMATE\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025-02-24-blog-1/blog-1.html",
    "href": "posts/2025-02-24-blog-1/blog-1.html",
    "title": "Blog 1: Data Progress",
    "section": "",
    "text": "Data #1: URL: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HLO4XC\nThe data comes from Kline, Patrick, Evan K. Rose, and Christopher R. Walters, “Systemic Discrimination Among Large U.S. Employers,” The Quarterly Journal of Economics, vol. 137 no. 4, (2022), 1963-2036.https://doi.org/10.1093/qje/qjac024. This dataset, published alongside the article by Kline, Rose, and Walters (2022), examines potential systemic hiring discrimination by large U.S. employers. The data primarily cover hiring outcomes, employer characteristics, and applicant demographic details spanning several years. Data is originally collected by authors. They conducted a randomized control trail (RCT) to identify patterns of potential discrimination, estimating the magnitude of these effects, and understanding whether certain employer or regional characteristics are associated with differential outcomes.\nData #2: URL: https://opportunityinsights.org/data/\nThe dataset described in College-Level Data for 139 Selective American Colleges provides insights into college application and attendance patterns among U.S. students based on parental income. Compiled by linking standardized test-takers (SAT or ACT from 2011, 2013, or 2015) to tax data, this dataset categorizes students into income bins to analyze disparities in college access. It covers 139 selective colleges, including Ivy-Plus institutions, elite private colleges, and flagship public universities. The dataset includes key metrics such as relative application rates, attendance rates, and conditional attendance rates, allowing researchers to examine how income influences higher education opportunities.\nA challenge in working with this dataset is its reliance on estimated values, as noise has been added for privacy reasons, potentially affecting precision. Additionally, while the dataset is rich in application and attendance statistics, it does not include direct measures of student academic performance beyond standardized test scores, limiting deeper analysis of post-admission outcomes.\nData #3 URL: https://www.samhsa.gov/data/data-we-collect/teds-treatment-episode-data-set/datafiles The Treatment Episode Data Set (TEDS), available through the SAMHSA website (TEDS Data Files), provides comprehensive data on individuals entering substance abuse treatment programs across the U.S. It includes over 2 million treatment episodes, with rows representing individual treatment episodes and columns covering demographics, substance use types, treatment modalities, and outcomes. The data is collected through state-administered systems in federally-funded treatment centers, aiming to monitor patterns of substance use, treatment needs, and outcomes. This standardized collection allows for detailed analysis of treatment trends across different regions and populations.\nWhile the dataset is available in multiple formats such as SAS, SPSS, and ASCII, loading and cleaning the data may require addressing missing values, ensuring proper data type conversion, and standardizing categories. A few key questions that can be explored include how treatment outcomes vary by demographics and how substance abuse trends differ across states and over time. Challenges may include the large size of the dataset, handling missing data, and ensuring confidentiality with sensitive information."
  },
  {
    "objectID": "posts/2025-03-17-blog-2/blog-2.html",
    "href": "posts/2025-03-17-blog-2/blog-2.html",
    "title": "Blog 2: Data Loading, Cleaning, and Diagnostic Plots",
    "section": "",
    "text": "This project uses data from the study “Systemic Discrimination Among Large U.S. Employers” by Patrick Kline, Evan K. Rose, and Christopher Walters (2022). The study examines discrimination in hiring practices through a large-scale correspondence experiment. Key aspects of the study include:\n\nObjective: To detect whether disparate treatment in hiring—particularly based on race, gender, and age—is concentrated within specific companies.\nDesign: A targeted randomized control trial where fictitious applications (varying by race, gender, and other resume characteristics) were submitted to over 100 Fortune 500 firms across multiple waves (including during the COVID pandemic).\nScale: Over 84,000 applications were sent, enabling both firm-level and industry-level analysis of callback rates.\nContext: The data is used to measure systemic discrimination, a term defined by patterns or practices with a broad impact on an industry or geographic area, and to provide actionable intelligence for policy enforcement (e.g., EEOC investigations).\n\nThis background provides important context on both the experimental design and the intended use of the data, highlighting potential challenges such as sample bias and variability across firms.\nIn this post, I describe the initial steps for loading and cleaning the dataset. I begin by reading in the cleaned data from an RDS file. The dataset contains various variables, including age_at_sub, month, year, and state, which I will explore to understand data quality and identify potential issues. Below is some sample R code I developed to generate diagnostic plots. I create a histogram to visualize the distribution of submissions throughout the months, faceted by year.\n\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")"
  },
  {
    "objectID": "posts/2025-03-17-blog-2/blog-2.html#data-background",
    "href": "posts/2025-03-17-blog-2/blog-2.html#data-background",
    "title": "Blog 2: Data Loading, Cleaning, and Diagnostic Plots",
    "section": "",
    "text": "This project uses data from the study “Systemic Discrimination Among Large U.S. Employers” by Patrick Kline, Evan K. Rose, and Christopher Walters (2022). The study examines discrimination in hiring practices through a large-scale correspondence experiment. Key aspects of the study include:\n\nObjective: To detect whether disparate treatment in hiring—particularly based on race, gender, and age—is concentrated within specific companies.\nDesign: A targeted randomized control trial where fictitious applications (varying by race, gender, and other resume characteristics) were submitted to over 100 Fortune 500 firms across multiple waves (including during the COVID pandemic).\nScale: Over 84,000 applications were sent, enabling both firm-level and industry-level analysis of callback rates.\nContext: The data is used to measure systemic discrimination, a term defined by patterns or practices with a broad impact on an industry or geographic area, and to provide actionable intelligence for policy enforcement (e.g., EEOC investigations).\n\nThis background provides important context on both the experimental design and the intended use of the data, highlighting potential challenges such as sample bias and variability across firms.\nIn this post, I describe the initial steps for loading and cleaning the dataset. I begin by reading in the cleaned data from an RDS file. The dataset contains various variables, including age_at_sub, month, year, and state, which I will explore to understand data quality and identify potential issues. Below is some sample R code I developed to generate diagnostic plots. I create a histogram to visualize the distribution of submissions throughout the months, faceted by year.\n\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")"
  },
  {
    "objectID": "posts/2025-03-17-blog-2/blog-2.html#check-distribution-of-submission-month-throughout-years",
    "href": "posts/2025-03-17-blog-2/blog-2.html#check-distribution-of-submission-month-throughout-years",
    "title": "Blog 2: Data Loading, Cleaning, and Diagnostic Plots",
    "section": "Check distribution of submission month throughout years",
    "text": "Check distribution of submission month throughout years\n\nggplot(data, aes(x = month)) +\n  geom_histogram(binwidth = 0.5, fill = \"skyblue\", color = \"black\") +  \n  scale_x_continuous(\n    breaks = 1:12,\n    labels = month.abb\n  ) +\n  labs(\n    title = \"Distribution of Months\",\n    x = \"Month\",\n    y = \"Count\"\n  ) +\n  theme(axis.text.x = element_text(angle = 45)) +\n  facet_grid(~year)\n\n\n\n\n\n\n\n\nThis plot shows sparse activity in early 2019, with submissions only appearing in a couple of months. In 2020, there is a notable increase, particularly in the latter half of the year. The highest volume of submissions occurs in early 2021, creating a distinct peak in the data. Overall, the distribution suggests that most of the data collection took place from late 2020 into the first months of 2021."
  },
  {
    "objectID": "posts/2025-04-22-blog-7/blog-7.html",
    "href": "posts/2025-04-22-blog-7/blog-7.html",
    "title": "Blog 7: Interactive Analysis",
    "section": "",
    "text": "Key objectives:\n\nHigh-level overview: Understand the names of the fake resumes and their callback rates.\nInteractive deep dive: Allow users to explore naming patterns and callback rates by race and gender.\n\n\n# Clear workspace\nrm(list = ls())\n\n\nInteractive Dashboard\nBelow is a self-contained Shiny app chunk that will render directly in your Quarto site using shinylive.\nInstructions:\n- 🔹 Self-contained: All libraries and data loading happen within this chunk.\n- 🔹 Small data: The RDS file is hosted on GitHub Pages for fast loading.\n\n# ```{shinylive-r} when ready to publish\nlibrary(shiny)\n\nWarning: package 'shiny' was built under R version 4.3.3\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(readr)\nlibrary(wordcloud2)\nlibrary(stringdist)\n\noptions(\"readr.edition\" = 1) # keep this to ensure you can download the data\ndata &lt;- read_rds(\"https://sussmanbu.github.io/ma4615-sp25-final-project-teamate/dataset_for_shiny/cleaned_data.rds\")\n\n\n# Define UI for app\nui &lt;- fluidPage(\n  titlePanel(\"Interactive Name Analysis Dashboard\"),\n  sidebarLayout(\n    sidebarPanel(\n      h4(\"Word Cloud Settings\"),\n      selectInput(\"race_wc\", \"Select Race:\", choices = sort(unique(data$race)), selected = \"White\"),\n      selectInput(\"gender_wc\", \"Select Gender:\", choices = sort(unique(data$gender)), selected = unique(data$gender)[1])\n    ),\n    mainPanel(\n      wordcloud2Output(\"name_wc\", width = \"100%\", height = \"600px\"),\n      br(),\n      h4(\"Top Names by Callback Rate\"),\n      tableOutput(\"top_callbacks\")\n    )\n  )\n)\n\n# Define server logic required to draw --\nserver &lt;- function(input, output, session) {\n  filtered_wc &lt;- reactive({\n    req(input$race_wc, input$gender_wc)\n    data %&gt;% filter(race == input$race_wc, gender == input$gender_wc)\n  })\n\n  \n  output$name_wc &lt;- renderWordcloud2({\n    df &lt;- filtered_wc() %&gt;%\n      count(firstname) %&gt;%\n      arrange(desc(n)) %&gt;%\n      head(100)\n    wordcloud2(df, size = 1)\n  })\n\n\n  output$top_callbacks &lt;- renderTable({\n    df &lt;- filtered_wc() %&gt;%\n      group_by(firstname) %&gt;%\n      summarise(\n        callback_rate = mean(cb, na.rm = TRUE),\n        count = n()\n      ) %&gt;%\n      arrange(desc(callback_rate), desc(count)) %&gt;%\n      head(10)\n    df\n  }, rownames = FALSE)\n}\n\n# Create Shiny app ----\nshinyApp(ui = ui, server = server)\n\nShiny applications not supported in static R Markdown documents\n\n\nDeployment tips:\n1. Confirm this chunk runs locally as a standard R chunk.\n2. Place the RDS file in your scripts/ folder and push to GitHub.\n3. Update the read_rds() URL to point to your published scripts/ location.\n4. Change the chunk engine to shinylive-r and re-render the site.\n5. Adjust viewerHeight as needed to fit your page layout.\nThis interactive component complements the static analysis by letting readers examine names and callback patterns directly by subgroup."
  },
  {
    "objectID": "posts/2025-04-14-blog-6/blog-6.html",
    "href": "posts/2025-04-14-blog-6/blog-6.html",
    "title": "Blog 6: Wrapping Up the Analysis",
    "section": "",
    "text": "This post replicates the table 1 and 2 in the paper in R.\nNote: Experiment data is from 2019-2021, while census data is from 2019-2024. The following code aggregate application level data to the state level and merge it with the census data to calculate the proportion of applications by state.\nThis exercise will help us understand the background of the data on a state-by-state basis and explore the relationship between callback rates and other variables at the state level.\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\nsuppressPackageStartupMessages(library(fixest))\nsuppressPackageStartupMessages(library(usmap))\nsuppressPackageStartupMessages(library(lfe))    \nsuppressPackageStartupMessages(library(lmtest))\nsuppressPackageStartupMessages(library(sandwich)) \nsuppressPackageStartupMessages(library(multiwayvcov))\n\n\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")"
  },
  {
    "objectID": "posts/2025-04-14-blog-6/blog-6.html#data-background-and-context",
    "href": "posts/2025-04-14-blog-6/blog-6.html#data-background-and-context",
    "title": "Blog 6: Wrapping Up the Analysis",
    "section": "Data Background and Context",
    "text": "Data Background and Context\nThe dataset originates from the landmark study “Systemic Discrimination Among Large U.S. Employers” (Kline, Rose, and Walters, 2022).\n\nResearch Questions: The study explores whether discrimination is endemic to particular firms, investigates firm-level heterogeneity in callback rates, and considers the potential impact of industry, geographic location, and other structural factors.\n\nThe census data was retrieved from the United States Census Bureau at this link: https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html\n\nfor(k in 1:4) {\n  data[[paste0(\"region4_\", k)]] &lt;- as.integer(data$region4 == k)\n}\n\nfor(k in 1:5) {\n  data[[paste0(\"wave\", k)]] &lt;- as.integer(data$wave == k)\n}"
  },
  {
    "objectID": "posts/2025-04-07-blog-5/blog-5.html",
    "href": "posts/2025-04-07-blog-5/blog-5.html",
    "title": "Blog 5: Geographic Analysis of Experiment and Census Data",
    "section": "",
    "text": "This code continues the same procedure as the previous blog, focusing on the analysis of a combined state-by-year dataset.\nNote: Experiment data is from 2019-2021, while census data is from 2019-2024. The following code aggregate application level data to the state level and merge it with the census data to calculate the proportion of applications by state.\nThis exercise will help us understand the background of the data on a state-by-state basis and explore the relationship between callback rates and other variables at the state level.\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\nsuppressPackageStartupMessages(library(fixest))\nsuppressPackageStartupMessages(library(usmap))\n\n\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")\ncensus_data &lt;- read_excel('dataset/NST-EST2024-POP.xlsx')\n\nNew names:\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`\n\ncensus_data_2 &lt;- read_excel('dataset/nst-est2019-01.xlsx', skip = 3)\n\nNew names:\n• `` -&gt; `...1`\n\n# for census_data_2 only keep year column 13 and row 6 onwards\ncensus_data_2 &lt;- census_data_2 %&gt;%\n  select(1, 13) %&gt;%\n  slice(6:56) \n\n# rename first column to states \ncolnames(census_data_2)[1] &lt;- \"states\"\n\n# delete . in front of state names\ncensus_data_2 &lt;- census_data_2 %&gt;% \n  filter(grepl(\"^\\\\.\", states)) %&gt;%\n  mutate(states = gsub(\"^\\\\.\", \"\", states))"
  },
  {
    "objectID": "posts/2025-04-07-blog-5/blog-5.html#data-background-and-context",
    "href": "posts/2025-04-07-blog-5/blog-5.html#data-background-and-context",
    "title": "Blog 5: Geographic Analysis of Experiment and Census Data",
    "section": "Data Background and Context",
    "text": "Data Background and Context\nThe dataset originates from the landmark study “Systemic Discrimination Among Large U.S. Employers” (Kline, Rose, and Walters, 2022).\n\nResearch Questions: The study explores whether discrimination is endemic to particular firms, investigates firm-level heterogeneity in callback rates, and considers the potential impact of industry, geographic location, and other structural factors.\n\nThe census data was retrieved from the United States Census Bureau at this link: https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html"
  },
  {
    "objectID": "posts/2025-03-31-blog-4/blog-4.html",
    "href": "posts/2025-03-31-blog-4/blog-4.html",
    "title": "Blog 4: Extended Statistical Modeling",
    "section": "",
    "text": "Note: Experiment data is from 2019-2021, while census data is from 2019-2024. The following code aggregate application level data to the state level and merge it with the census data to calculate the proportion of applications by state.\nThis exercise will help us understand the background of the data on a state-by-state basis and explore the relationship between callback rates and other variables at the state level.\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\nsuppressPackageStartupMessages(library(fixest))\n\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")\ncensus_data &lt;- read_excel('dataset/NST-EST2024-POP.xlsx')\n\nNew names:\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`\n\ncensus_data_2 &lt;- read_excel('dataset/nst-est2019-01.xlsx', skip = 3)\n\nNew names:\n• `` -&gt; `...1`\n\n# for census_data_2 only keep year column 13 and row 6 onwards\ncensus_data_2 &lt;- census_data_2 %&gt;%\n  select(1, 13) %&gt;%\n  slice(6:56) \n\n# rename first column to states \ncolnames(census_data_2)[1] &lt;- \"states\"\n\n# delete . in front of state names\ncensus_data_2 &lt;- census_data_2 %&gt;% \n  filter(grepl(\"^\\\\.\", states)) %&gt;%\n  mutate(states = gsub(\"^\\\\.\", \"\", states))"
  },
  {
    "objectID": "posts/2025-03-31-blog-4/blog-4.html#data-background-and-context",
    "href": "posts/2025-03-31-blog-4/blog-4.html#data-background-and-context",
    "title": "Blog 4: Extended Statistical Modeling",
    "section": "Data Background and Context",
    "text": "Data Background and Context\nThe dataset originates from the landmark study “Systemic Discrimination Among Large U.S. Employers” (Kline, Rose, and Walters, 2022).\n\nResearch Questions: The study explores whether discrimination is endemic to particular firms, investigates firm-level heterogeneity in callback rates, and considers the potential impact of industry, geographic location, and other structural factors.\n\nThe census data was retrieved from the United States Census Bureau at this link: https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html"
  },
  {
    "objectID": "posts/2025-03-24-blog-3/blog-3.html",
    "href": "posts/2025-03-24-blog-3/blog-3.html",
    "title": "Blog 3: Extended Analysis and Equity Considerations",
    "section": "",
    "text": "rm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\n\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")\ncensus_data &lt;- read_excel('dataset/NST-EST2024-POP.xlsx')\n\nNew names:\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`"
  },
  {
    "objectID": "posts/2025-03-24-blog-3/blog-3.html#data-background-and-context",
    "href": "posts/2025-03-24-blog-3/blog-3.html#data-background-and-context",
    "title": "Blog 3: Extended Analysis and Equity Considerations",
    "section": "Data Background and Context",
    "text": "Data Background and Context\nThe dataset originates from the landmark study “Systemic Discrimination Among Large U.S. Employers” (Kline, Rose, and Walters, 2022).\n\nResearch Questions: The study explores whether discrimination is endemic to particular firms, investigates firm-level heterogeneity in callback rates, and considers the potential impact of industry, geographic location, and other structural factors.\n\nThe census data was retrieved from the United States Census Bureau at this link: https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html"
  },
  {
    "objectID": "posts/2025-03-24-blog-3/blog-3.html#extended-exploratory-analysis-and-equity-considerations",
    "href": "posts/2025-03-24-blog-3/blog-3.html#extended-exploratory-analysis-and-equity-considerations",
    "title": "Blog 3: Extended Analysis and Equity Considerations",
    "section": "Extended Exploratory Analysis and Equity Considerations",
    "text": "Extended Exploratory Analysis and Equity Considerations\nIn this update, I extend my analysis to delve deeper into the structure of the data and highlight important equity issues. By examining the distribution of submissions by state and comparing callback rates by race, the analysis aims to uncover potential systemic biases and inform further steps."
  },
  {
    "objectID": "posts/2025-03-24-blog-3/blog-3.html#check-distribution-of-submissions-by-state",
    "href": "posts/2025-03-24-blog-3/blog-3.html#check-distribution-of-submissions-by-state",
    "title": "Blog 3: Extended Analysis and Equity Considerations",
    "section": "Check distribution of submissions by state",
    "text": "Check distribution of submissions by state\nThe following code creates a bar plot that orders states by the count of submissions. This visualization helps identify geographic patterns in the data, which may be related to regional hiring practices or other local factors.\n\ndata %&gt;%\n  count(state) %&gt;%\n  arrange(desc(n)) %&gt;% \n  ggplot(aes(y = reorder(state, n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribution of States (Ordered by Count)\",\n    y = \"State\",\n    x = \"Count\"\n  )"
  },
  {
    "objectID": "posts/2025-03-24-blog-3/blog-3.html#check-distribution-of-population-by-state",
    "href": "posts/2025-03-24-blog-3/blog-3.html#check-distribution-of-population-by-state",
    "title": "Blog 3: Extended Analysis and Equity Considerations",
    "section": "Check distribution of population by state",
    "text": "Check distribution of population by state\nThe following code organizes data from the U.S. Census Bureau and creates a bar plot that orders states by their population in 2024. This visualization highlights the distribution of population density across states, providing a clear comparison to the research data. By aligning the population data with the research findings, the plot demonstrates a correlation between states with higher populations and the number of samples collected in those states.\n\ncolnames(census_data)[1] &lt;- \"states\"\n\ncensus_data &lt;- census_data %&gt;% \n  select(-2) %&gt;% \n  slice(-(1:3))\n\ncolnames(census_data)[2:6] &lt;- c(\"2020\", \"2021\", \"2022\", \"2023\", \"2024\")\n\ncensus_data &lt;- census_data %&gt;% filter(grepl(\"^\\\\.\", states))\n\ncensus_data &lt;- census_data %&gt;% \n  filter(states != \".Puerto Rico\") %&gt;%\n  mutate(states = gsub(\"^\\\\.\", \"\", states)) \n\ncensus_data %&gt;%\n  ggplot(aes(y = reorder(states, `2024`), x = `2024`)) +  # Use backticks for column names\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Population Distribution by State (2024)\",\n    y = \"State\",\n    x = \"Population\"\n  )"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team TEAMATE.\nThe members of this team are below."
  },
  {
    "objectID": "about.html#acknowledgements",
    "href": "about.html#acknowledgements",
    "title": "About",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis is a course project for MA[46]15 Data Science with R at the Boston University. We thank Professor Daniel Sussman and TF Aislinn Sullivan for their guidance and support throughout the course. We also thank our classmates for their feedback. The content and assessments for this course have been modified as part of Boston University’s Designing Antiracist Curricula Fellowship.\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "How much does your identity matter in landing an interview?\nMedia coverage of this study by Kline, Rose, and Walters, 2022:\nNew York Times\nMarketplace\nHere & Now\nYoutube Channel: econimate\nThis comes from the file big_picture.qmd.\nIn today’s competitive job market, a candidate’s name can be an unexpected gatekeeper.\nResumes bearing names commonly associated with different racial or gender groups may receive different callback rates—even when qualifications are identical.\nThat’s the hidden bias we set out to uncover.\n&gt; Note: Sacred Journey by Michael Reeder: An Art Piece that represents the journey of self-discovery and identity."
  },
  {
    "objectID": "big_picture.html#data",
    "href": "big_picture.html#data",
    "title": "Big Picture",
    "section": "Data",
    "text": "Data\nWe used data from the study “Systemic Discrimination Among Large U.S. Employers” by Kline, Rose, and Walters (2022). The study examines discrimination in hiring practices through a large-scale correspondence experiment. Key aspects of the study include:\n\nsending over 84,000 fictitious applications to over 100 Fortune 500 firms across multiple waves (including during the COVID pandemic).\nThe data is used to measure systemic discrimination, a term defined by patterns or practices with a broad impact on an industry or geographic area, and to provide actionable intelligence for policy enforcement (e.g., EEOC investigations).\n\nThis is an example of how a sample of resumes looks like: \n\nNote: sourced from Figure A1: Examples of applicant resumes in the Rose et al. (2022) paper.\n\n\n\nExplore it yourself\nThe interactive below lets you select any racial group and gender to view:\n\nA word cloud of the top first names in that subgroup.\n\nA table of the top names ranked by callback rate.\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| eval: true\n#| standalone: true\n#| viewerHeight: 640\n# ```{shinylive-r} when ready to publish\nlibrary(shiny)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(wordcloud2)\nlibrary(stringdist)\n\noptions(\"readr.edition\" = 1) # keep this to ensure you can download the data\ndata &lt;- read_rds(\"https://sussmanbu.github.io/ma4615-sp25-final-project-teamate/dataset_for_shiny/cleaned_data.rds\")\n\n\n# Define UI for app\nui &lt;- fluidPage(\n  titlePanel(\"Interactive Name Analysis Dashboard\"),\n  sidebarLayout(\n    sidebarPanel(\n      h4(\"Word Cloud Settings\"),\n      selectInput(\"race_wc\", \"Select Race:\", choices = sort(unique(data$race)), selected = \"White\"),\n      selectInput(\"gender_wc\", \"Select Gender:\", choices = sort(unique(data$gender)), selected = unique(data$gender)[1]),\n      br(),\n      h4(\"Top Names by Callback Rate\"),\n      tableOutput(\"top_callbacks\")\n    ),\n    mainPanel(\n      wordcloud2Output(\"name_wc\", width = \"100%\", height = \"600px\")\n    )\n  )\n)\n\n# Define server logic required to draw --\nserver &lt;- function(input, output, session) {\n  filtered_wc &lt;- reactive({\n    req(input$race_wc, input$gender_wc)\n    data %&gt;% filter(race == input$race_wc, gender == input$gender_wc)\n  })\n\n  \n  output$name_wc &lt;- renderWordcloud2({\n    df &lt;- filtered_wc() %&gt;%\n      count(firstname) %&gt;%\n      arrange(desc(n)) %&gt;%\n      head(100)\n    \n    set.seed(123)\n    wordcloud2(df, size = 1)\n  })\n\n\n  output$top_callbacks &lt;- renderTable({\n    df &lt;- filtered_wc() %&gt;%\n      group_by(firstname) %&gt;%\n      summarise(\n        callback_rate = mean(cb, na.rm = TRUE)#,\n        #count = n()\n      ) %&gt;%\n      arrange(desc(callback_rate), \n              #desc(count)\n              ) %&gt;%\n      head(10)\n    df\n  }, rownames = FALSE)\n}\n\n# Create Shiny app ----\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "big_picture.html#descriptive-evidence-by-applicants-first-name",
    "href": "big_picture.html#descriptive-evidence-by-applicants-first-name",
    "title": "Big Picture",
    "section": "Descriptive Evidence by Applicants First Name",
    "text": "Descriptive Evidence by Applicants First Name\n\nThis figure shows mean contact rates by applicant first name, organized by race group. The horizontal bars show race group mean contact rates. We can see that, on average, black names receive fewer 30-day callbacks than white names.\nTo get the shinylive-r working.\n\nMake sure your shiny app works as a regular r chunk.\nMake sure that the chunk is completely self-contained. Meaning all packages and data are loaded inside that chunk. It can’t rely on any other chunks.\nFor the data that you are using for shiny, copy the rds file or any other files into the scripts folder, and then publish your website.\nWhere you load in your data, change it to use a URL to the data set which will now be on your website. Something like read_rds(“https://sussmanbu.github.io/ma-4615-fa24-final-project-group-a/scripts/dataset_for_shiny.rds”)\nCheck that the chunk still works as a regular r chunk.\nChange it to a shinylive-r chunk.\nCommit and publish your work.\n\nI recommend keeping the data used for the shiny interactive relatively small, though this isn’t completely necessary."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a how a news article or a magazine story might draw you in. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nInteractive component\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions?\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  }
]